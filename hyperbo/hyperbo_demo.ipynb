{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyFIhMwHuwb5"
      },
      "source": [
        "\u003ca href=\"https://colab.research.google.com/github/google-research/hyperbo/blob/main/hyperbo/hyperbo_demo.ipynb\" target=\"_parent\"\u003e\u003cimg src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/\u003e\u003c/a\u003e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laIKNd5OuAxo"
      },
      "source": [
        "##### Copyright 2023 HyperBO Authors.\n",
        "Licensed under the Apache License, Version 2.0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZ0O6z485eVr"
      },
      "outputs": [],
      "source": [
        "# Copyright 2023 HyperBO Authors.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hb6a7OD5n4H"
      },
      "source": [
        "# HyperBO Codelab Notebook\n",
        "This notebook is an example of how to define and pre-train Gaussian process (GP) models in HyperBO.\n",
        "\n",
        "[Research paper](https://arxiv.org/abs/2109.08215) | [GitHub repository](https://github.com/google-research/hyperbo/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "AiMXJRVKvgg6"
      },
      "outputs": [],
      "source": [
        "#@title Install HyperBO from GitHub\n",
        "!pip install git+https://github.com/google-research/hyperbo.git \u003e\u003e out.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "3WXpfKFDv-Aq"
      },
      "outputs": [],
      "source": [
        "# @title Imports and some utilities for plotting\n",
        "import random\n",
        "import time\n",
        "\n",
        "from hyperbo.basics import definitions as defs\n",
        "from hyperbo.basics import params_utils\n",
        "from hyperbo.gp_utils import gp\n",
        "from hyperbo.gp_utils import kernel\n",
        "from hyperbo.gp_utils import mean\n",
        "from hyperbo.gp_utils import utils\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "font = {\n",
        "    'family': 'serif',\n",
        "    'weight': 'normal',\n",
        "    'size': 7,\n",
        "}\n",
        "axes = {'titlesize': 7, 'labelsize': 7}\n",
        "matplotlib.rc('font', **font)\n",
        "matplotlib.rc('axes', **axes)\n",
        "\n",
        "DEFAULT_WARP_FUNC = utils.DEFAULT_WARP_FUNC\n",
        "GPParams = defs.GPParams\n",
        "SubDataset = defs.SubDataset\n",
        "\n",
        "\n",
        "def plot_function_samples(\n",
        "    mean_func,\n",
        "    cov_func,\n",
        "    params,\n",
        "    warp_func=None,\n",
        "    num_samples=1,\n",
        "    random_seed=0,\n",
        "    x_min=0,\n",
        "    x_max=1,\n",
        "):\n",
        "  \"\"\"Plot function samples from a 1-D Gaussian process.\n",
        "\n",
        "  Args:\n",
        "    mean_func: mean function handle that maps from (params, n x d input,\n",
        "      warp_func) to an n dimensional mean vector. (see vector_map in\n",
        "      gp_utils/mean.py for more details).\n",
        "    cov_func: covariance function handle that maps from (params, n1 x d input1,\n",
        "      n2 x d input2, wrap_func) to a n1 x n2  covariance matrix (see matrix_map\n",
        "      in gp_utils/kernel.py for more details).\n",
        "    params: GPParams, parameters for covariance, mean, and noise variance.\n",
        "    warp_func: optional dictionary that specifies the warping function for each\n",
        "      parameter.\n",
        "    num_samples: number of draws from the 1-D Gaussian process.\n",
        "    random_seed: random seed for sampling.\n",
        "    x_min: the min of the range of x.\n",
        "    x_max: the max of the range of x.\n",
        "  \"\"\"\n",
        "  key = jax.random.PRNGKey(random_seed)\n",
        "  key, y_key = jax.random.split(key, 2)\n",
        "  x = jnp.linspace(x_min, x_max, 100)[:, None]\n",
        "  y = gp.sample_from_gp(\n",
        "      y_key,\n",
        "      mean_func,\n",
        "      cov_func,\n",
        "      params,\n",
        "      x,\n",
        "      warp_func=warp_func,\n",
        "      num_samples=num_samples,\n",
        "      method='svd',\n",
        "  )\n",
        "  fig = plt.figure(dpi=200, figsize=(2, 1))\n",
        "  plt.plot(x, y)\n",
        "  plt.xlabel('x')\n",
        "  plt.ylabel('f(x)')\n",
        "\n",
        "\n",
        "def plot_training_data(dataset, loss_function, num_samples=3, random_seed=0):\n",
        "  \"\"\"Plot datapoints from each (sampled) training function on a 1-D input space.\n",
        "\n",
        "  Args:\n",
        "    dataset: Dict[Union[int, str], SubDataset], a dictionary mapping from key to\n",
        "      SubDataset.\n",
        "    loss_function: 'nll' or 'ekl'. If loss_function is 'nll', only plot generic\n",
        "      training data. If 'ekl', only plot matching-input training data.\n",
        "    num_samples: the number of sub-datasets to be plotted.\n",
        "    random_seed: random seed used to sample sub-datasets for plotting.\n",
        "  \"\"\"\n",
        "  print(f'Using the {loss_function} loss function.')\n",
        "  def plot(dataset):\n",
        "    random.shuffle(dataset)\n",
        "    cnt = 0\n",
        "    fig = plt.figure(dpi=200, figsize=(2, 1))\n",
        "    for subdataset in dataset:\n",
        "      if cnt == num_samples:\n",
        "        break\n",
        "      plt.scatter(subdataset.x, subdataset.y, s=1)\n",
        "      cnt += 1\n",
        "    plt.xlabel('x')\n",
        "    plt.ylabel('f(x)')\n",
        "\n",
        "  if loss_function == 'nll':\n",
        "    dataset = [d for d in dataset.values() if d.aligned is None]\n",
        "  elif loss_function == 'ekl':\n",
        "    aligned_dataset = [d for d in dataset.values() if d.aligned is not None]\n",
        "    dataset = []\n",
        "    for subdataset in aligned_dataset:\n",
        "      for i in range(subdataset.y.shape[1]):\n",
        "        d = SubDataset(x=subdataset.x, y=subdataset.y[:, i:i+1])\n",
        "        dataset.append(d)\n",
        "  else:\n",
        "    raise ValueError(f'{loss_function} is not a valid loss function.')\n",
        "  print(f'dataset has {len(dataset)} training functions in total.')\n",
        "  info = ''\n",
        "  if num_samples \u003e= len(dataset):\n",
        "    num_samples = len(dataset)\n",
        "  else:\n",
        "    info = 'randomly sampled '\n",
        "  print(f'Visualizing data from {num_samples} {info}training functions.')\n",
        "  plot(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xsR97tRs72qU"
      },
      "outputs": [],
      "source": [
        "# @title Define a ground truth GP and generate training data\n",
        "params = GPParams(\n",
        "    model={\n",
        "        'lengthscale': 0.1,\n",
        "        'signal_variance': 10.0,\n",
        "        'noise_variance': 1e-6,\n",
        "        'constant': 5.0,\n",
        "    }\n",
        ")  # parameters of the GP\n",
        "\n",
        "\n",
        "def ground_truth_mean_func(params, x, warp_func=None):\n",
        "  return -jax.nn.relu(x - 0.5) * 20\n",
        "\n",
        "\n",
        "mean_func = ground_truth_mean_func  # mean function of the GP\n",
        "cov_func = kernel.matern52  # kernel (covariance) function of the GP\n",
        "\n",
        "random_seed = 10  #@param{type: \"number\", isTemplate: true}\n",
        "key = jax.random.PRNGKey(random_seed)\n",
        "# number of training functions\n",
        "num_train_functions = 10  #@param{type: \"number\", isTemplate: true}\n",
        "# number of datapoints per training function\n",
        "num_datapoints_per_train_function = 10  #@param{type: \"number\", isTemplate: true}\n",
        "\n",
        "dataset = {}  # Training dataset\n",
        "# Generate generic training data (only used by NLL)\n",
        "for sub_dataset_id in range(num_train_functions):\n",
        "  key, x_key, y_key = jax.random.split(key, 3)\n",
        "  x = jax.random.uniform(x_key, (num_datapoints_per_train_function, 1))\n",
        "  y = gp.sample_from_gp(y_key, mean_func, cov_func, params, x, method='svd')\n",
        "  dataset[str(sub_dataset_id)] = SubDataset(x, y)\n",
        "# Generate matching-input training data (only used by EKL)\n",
        "key, x_key, y_key = jax.random.split(key, 3)\n",
        "x = jax.random.uniform(x_key, (num_datapoints_per_train_function, 1))\n",
        "y = gp.sample_from_gp(\n",
        "    y_key,\n",
        "    mean_func,\n",
        "    cov_func,\n",
        "    params,\n",
        "    x,\n",
        "    num_samples=num_train_functions,\n",
        "    method='svd',\n",
        ")\n",
        "dataset['matching-input'] = SubDataset(x, y, aligned=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Tz2qoPdrw4KR"
      },
      "outputs": [],
      "source": [
        "#@title Visualize function samples from the ground truth GP\n",
        "random_seed = 0  #@param{type: \"number\", isTemplate: true}\n",
        "num_samples = 10  #@param{type: \"number\", isTemplate: true}\n",
        "plot_function_samples(mean_func,\n",
        "                      cov_func,\n",
        "                      params,\n",
        "                      num_samples=num_samples,\n",
        "                      random_seed=random_seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "24neW43b1upQ"
      },
      "outputs": [],
      "source": [
        "# @title Initialize a GP model to be pre-trained\n",
        "optimization_method = 'lbfgs'  # @param ['lbfgs', 'adam']\n",
        "loss_function = 'ekl'  # @param ['nll', 'ekl']\n",
        "max_training_step = 1000  #@param{type: \"number\", isTemplate: true}\n",
        "\n",
        "key = jax.random.PRNGKey(1)\n",
        "params = GPParams(\n",
        "    model={\n",
        "        'lengthscale': jnp.array([.0]),\n",
        "        'signal_variance': 0.0,\n",
        "        'noise_variance': -6.,\n",
        "    },\n",
        "    config={\n",
        "        'mlp_features': (8, 8),\n",
        "        'method': optimization_method,\n",
        "        'max_training_step': max_training_step,\n",
        "        'batch_size': 100,\n",
        "        'objective': loss_function if loss_function == 'nll' else 'kl',\n",
        "        'learning_rate': 1e-3,\n",
        "    },\n",
        ")\n",
        "mean_func = mean.linear_mlp\n",
        "cov_func = kernel.squared_exponential_mlp\n",
        "warp_func = DEFAULT_WARP_FUNC\n",
        "\n",
        "model = gp.GP(\n",
        "    dataset=dataset,\n",
        "    params=params,\n",
        "    mean_func=mean_func,\n",
        "    cov_func=cov_func,\n",
        "    warp_func=warp_func,\n",
        ")\n",
        "\n",
        "key, subkey = jax.random.split(key, 2)\n",
        "model.initialize_params(subkey)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "OlMvNePKP-As"
      },
      "outputs": [],
      "source": [
        "#@title Visualize function samples from the initialized GP\n",
        "random_seed = 3  #@param{type: \"number\", isTemplate: true}\n",
        "num_samples = 5  #@param{type: \"number\", isTemplate: true}\n",
        "plot_function_samples(model.mean_func,\n",
        "                      model.cov_func,\n",
        "                      model.params,\n",
        "                      num_samples=num_samples,\n",
        "                      warp_func=warp_func,\n",
        "                      random_seed=random_seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "T9NuSua_z-ug"
      },
      "outputs": [],
      "source": [
        "#@title Visualize training data\n",
        "random_seed = 3  #@param{type: \"number\", isTemplate: true}\n",
        "num_samples = 5  #@param{type: \"number\", isTemplate: true}\n",
        "plot_training_data(model.dataset,\n",
        "                   loss_function,\n",
        "                   num_samples=num_samples,\n",
        "                   random_seed=random_seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "FlKFAbV5Eizc"
      },
      "outputs": [],
      "source": [
        "#@title Pre-train the GP (you can run more than once to train for more steps)\n",
        "print('Before pre-training.')\n",
        "_ = model.stats()\n",
        "start = time.time()\n",
        "print('Pre-training..')\n",
        "trained_params = model.train()\n",
        "print(f'Pre-training time (s): {time.time() - start}')\n",
        "print('After pre-training.')\n",
        "_ = model.stats()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "OsXs6dQpNffl"
      },
      "outputs": [],
      "source": [
        "#@title Visualize function samples from the pre-trained GP\n",
        "random_seed = 0  #@param{type: \"number\", isTemplate: true}\n",
        "num_samples = 10  #@param{type: \"number\", isTemplate: true}\n",
        "plot_function_samples(model.mean_func,\n",
        "                      model.cov_func,\n",
        "                      model.params,\n",
        "                      num_samples=num_samples,\n",
        "                      warp_func=warp_func,\n",
        "                      random_seed=random_seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "hHRqJ78DZ2ym"
      },
      "outputs": [],
      "source": [
        "#@title Print pre-trained model parameters (only the interpretable ones)\n",
        "lengthscale, signal_variance, noise_variance = params_utils.retrieve_params(model.params, ['lengthscale', 'signal_variance', 'noise_variance'], warp_func)\n",
        "print(f'lengthscale={lengthscale} signal_variance={signal_variance} noise_variance={noise_variance}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1ezJIor087M"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "laIKNd5OuAxo"
      ],
      "last_runtime": {
        "build_target": "//learning/deepmind/public/tools/ml_python:ml_notebook",
        "kind": "private"
      },
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "1j1sjlixsJznkQtxCW9kTHQX92LFAghQ-",
          "timestamp": 1680455479775
        }
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
